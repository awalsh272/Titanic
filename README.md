# Titanic
Kaggle's Titanic competition, just for messing around with sklearn, pandas, etc

After some data cleaning and EDA, ran logistic regression and random forests. Would like to try XGBoost and PCA at some point. Additionally, would like to try different imputation methods for missing data, as well as more robust feature selection/engineering. Should perhaps consider transforming some of the variables (log, boxcox), adding interaction terms, addressing multicollinearity between socio-economic status variables (PClass and Fare).
